# SBSPS-Challenge-10236-Slient-Speech-Recognition-Automatic-Lip-reading-Model-using-3D-CNN-and-GRU
Slient Speech Recognition : Automatic Lip reading Model using 3D CNN and GRU
ur solution utilizes advanced computer vision algorithms and machine learning models to capture and interpret sign language gestures in real-time. 
It ensures immediate translation, enabling smooth and natural conversations between sign language users and English speakers.
The system recognizes and interprets a wide range of sign language gestures, including hand movements, facial expressions, and body language. 
It accurately captures the nuances and intricacies of sign language, ensuring precise translation and effective communication.
The translated output is provided in both spoken words and written text formats, catering to the diverse needs and preferences of users. 
It allows sign language users to engage in spoken conversations and provides written text for situations where written communication is more appropriate or necessary.

We have used the GRID CORPUS data set for the development of our project.
Dataset link: https://zenodo.org/record/3625687
Document link:https://docs.google.com/document/d/1wnUBBha1NO5QLDAUvmaLTkiZrZYBLdOA/edit?usp=sharing&ouid=116463949653548343918&rtpof=true&sd=true


